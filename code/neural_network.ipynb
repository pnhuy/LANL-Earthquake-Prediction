{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/full_train_ft_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4195, 218)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4195, 213)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4195, 172)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns = df.columns[df.nunique() == 1])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3356, 171)\n",
      "(3356,)\n",
      "(839, 171)\n",
      "(839,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['time_to_failure']), df.time_to_failure, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,\n",
    "                    input_dim=X_train.shape[1],\n",
    "                    #kernel_initializer='normal',\n",
    "                    activation='relu'                   \n",
    "                   ))\n",
    "    model.add(Dense(1,\n",
    "                   #kernel_initializer='normal',\n",
    "                   activation='linear'\n",
    "                   ))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2019\n",
    "np.random.seed(seed)\n",
    "model = KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3356 samples, validate on 839 samples\n",
      "Epoch 1/50\n",
      "3356/3356 [==============================] - 1s 278us/step - loss: 18.6966 - val_loss: 12.8288\n",
      "Epoch 2/50\n",
      "3356/3356 [==============================] - 0s 69us/step - loss: 12.0608 - val_loss: 11.2766\n",
      "Epoch 3/50\n",
      "3356/3356 [==============================] - 0s 76us/step - loss: 10.5850 - val_loss: 9.8634\n",
      "Epoch 4/50\n",
      "3356/3356 [==============================] - 0s 64us/step - loss: 9.6256 - val_loss: 9.1892\n",
      "Epoch 5/50\n",
      "3356/3356 [==============================] - 0s 68us/step - loss: 9.0686 - val_loss: 8.9253\n",
      "Epoch 6/50\n",
      "3356/3356 [==============================] - 0s 74us/step - loss: 8.8007 - val_loss: 8.6355\n",
      "Epoch 7/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 8.5822 - val_loss: 8.8341\n",
      "Epoch 8/50\n",
      "3356/3356 [==============================] - 0s 66us/step - loss: 8.4628 - val_loss: 8.3880\n",
      "Epoch 9/50\n",
      "3356/3356 [==============================] - 0s 72us/step - loss: 8.4409 - val_loss: 8.3013\n",
      "Epoch 10/50\n",
      "3356/3356 [==============================] - 0s 64us/step - loss: 8.3230 - val_loss: 8.2208\n",
      "Epoch 11/50\n",
      "3356/3356 [==============================] - 0s 68us/step - loss: 8.2345 - val_loss: 8.1728\n",
      "Epoch 12/50\n",
      "3356/3356 [==============================] - 0s 74us/step - loss: 8.1108 - val_loss: 8.6322\n",
      "Epoch 13/50\n",
      "3356/3356 [==============================] - 0s 64us/step - loss: 8.0748 - val_loss: 8.1007\n",
      "Epoch 14/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 8.1074 - val_loss: 8.1157\n",
      "Epoch 15/50\n",
      "3356/3356 [==============================] - 0s 78us/step - loss: 7.9627 - val_loss: 8.0711\n",
      "Epoch 16/50\n",
      "3356/3356 [==============================] - 0s 81us/step - loss: 7.9814 - val_loss: 8.0132\n",
      "Epoch 17/50\n",
      "3356/3356 [==============================] - 0s 79us/step - loss: 8.0015 - val_loss: 7.9842\n",
      "Epoch 18/50\n",
      "3356/3356 [==============================] - 0s 66us/step - loss: 7.8747 - val_loss: 8.0099\n",
      "Epoch 19/50\n",
      "3356/3356 [==============================] - 0s 77us/step - loss: 7.8864 - val_loss: 7.9509\n",
      "Epoch 20/50\n",
      "3356/3356 [==============================] - 0s 79us/step - loss: 7.8773 - val_loss: 7.9443\n",
      "Epoch 21/50\n",
      "3356/3356 [==============================] - 0s 76us/step - loss: 7.9465 - val_loss: 7.9213\n",
      "Epoch 22/50\n",
      "3356/3356 [==============================] - 0s 81us/step - loss: 7.7570 - val_loss: 7.9376\n",
      "Epoch 23/50\n",
      "3356/3356 [==============================] - 0s 79us/step - loss: 7.8261 - val_loss: 7.8910\n",
      "Epoch 24/50\n",
      "3356/3356 [==============================] - 0s 72us/step - loss: 7.7229 - val_loss: 7.9889\n",
      "Epoch 25/50\n",
      "3356/3356 [==============================] - 0s 67us/step - loss: 7.7887 - val_loss: 7.9097\n",
      "Epoch 26/50\n",
      "3356/3356 [==============================] - 0s 66us/step - loss: 7.6932 - val_loss: 8.0118\n",
      "Epoch 27/50\n",
      "3356/3356 [==============================] - 0s 81us/step - loss: 7.7007 - val_loss: 8.0205\n",
      "Epoch 28/50\n",
      "3356/3356 [==============================] - 0s 75us/step - loss: 7.6935 - val_loss: 7.8410\n",
      "Epoch 29/50\n",
      "3356/3356 [==============================] - 0s 69us/step - loss: 7.6697 - val_loss: 7.8387\n",
      "Epoch 30/50\n",
      "3356/3356 [==============================] - 0s 78us/step - loss: 7.6672 - val_loss: 7.8510\n",
      "Epoch 31/50\n",
      "3356/3356 [==============================] - 0s 76us/step - loss: 7.6405 - val_loss: 7.9086\n",
      "Epoch 32/50\n",
      "3356/3356 [==============================] - 0s 67us/step - loss: 7.6230 - val_loss: 7.8043\n",
      "Epoch 33/50\n",
      "3356/3356 [==============================] - 0s 69us/step - loss: 7.6184 - val_loss: 7.9002\n",
      "Epoch 34/50\n",
      "3356/3356 [==============================] - 0s 75us/step - loss: 7.6067 - val_loss: 7.8131\n",
      "Epoch 35/50\n",
      "3356/3356 [==============================] - 0s 68us/step - loss: 7.5768 - val_loss: 7.9258\n",
      "Epoch 36/50\n",
      "3356/3356 [==============================] - 0s 81us/step - loss: 7.6368 - val_loss: 7.8909\n",
      "Epoch 37/50\n",
      "3356/3356 [==============================] - 0s 79us/step - loss: 7.5731 - val_loss: 7.9566\n",
      "Epoch 38/50\n",
      "3356/3356 [==============================] - 0s 76us/step - loss: 7.6690 - val_loss: 8.3389\n",
      "Epoch 39/50\n",
      "3356/3356 [==============================] - 0s 77us/step - loss: 7.6030 - val_loss: 7.7727\n",
      "Epoch 40/50\n",
      "3356/3356 [==============================] - 0s 76us/step - loss: 7.5731 - val_loss: 7.9812\n",
      "Epoch 41/50\n",
      "3356/3356 [==============================] - 0s 74us/step - loss: 7.5166 - val_loss: 7.7539\n",
      "Epoch 42/50\n",
      "3356/3356 [==============================] - 0s 67us/step - loss: 7.5241 - val_loss: 7.7434\n",
      "Epoch 43/50\n",
      "3356/3356 [==============================] - 0s 70us/step - loss: 7.5458 - val_loss: 7.7523\n",
      "Epoch 44/50\n",
      "3356/3356 [==============================] - 0s 82us/step - loss: 7.5337 - val_loss: 7.8157\n",
      "Epoch 45/50\n",
      "3356/3356 [==============================] - 0s 79us/step - loss: 7.4910 - val_loss: 7.7249\n",
      "Epoch 46/50\n",
      "3356/3356 [==============================] - 0s 82us/step - loss: 7.4764 - val_loss: 7.7536\n",
      "Epoch 47/50\n",
      "3356/3356 [==============================] - 0s 77us/step - loss: 7.6079 - val_loss: 7.7244\n",
      "Epoch 48/50\n",
      "3356/3356 [==============================] - 0s 70us/step - loss: 7.4891 - val_loss: 7.8593\n",
      "Epoch 49/50\n",
      "3356/3356 [==============================] - 0s 74us/step - loss: 7.4292 - val_loss: 7.7369\n",
      "Epoch 50/50\n",
      "3356/3356 [==============================] - 0s 83us/step - loss: 7.5498 - val_loss: 7.8250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca0bdfd208>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,\n",
    "                    input_dim=X_train.shape[1],\n",
    "                    #kernel_initializer='normal',\n",
    "                    activation='relu'                   \n",
    "                   ))\n",
    "    model.add(Dense(1,\n",
    "                   #kernel_initializer='normal',\n",
    "                   activation='linear'\n",
    "                   ))\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=64, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed:   42.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3356/3356 [==============================] - 1s 325us/step - loss: 16.4500\n",
      "Epoch 2/50\n",
      "3356/3356 [==============================] - 0s 63us/step - loss: 11.2647\n",
      "Epoch 3/50\n",
      "3356/3356 [==============================] - 0s 68us/step - loss: 9.7821\n",
      "Epoch 4/50\n",
      "3356/3356 [==============================] - 0s 64us/step - loss: 9.1398\n",
      "Epoch 5/50\n",
      "3356/3356 [==============================] - 0s 68us/step - loss: 8.6998\n",
      "Epoch 6/50\n",
      "3356/3356 [==============================] - 0s 61us/step - loss: 8.5479\n",
      "Epoch 7/50\n",
      "3356/3356 [==============================] - 0s 69us/step - loss: 8.3178\n",
      "Epoch 8/50\n",
      "3356/3356 [==============================] - 0s 69us/step - loss: 8.2160\n",
      "Epoch 9/50\n",
      "3356/3356 [==============================] - 0s 62us/step - loss: 8.0940\n",
      "Epoch 10/50\n",
      "3356/3356 [==============================] - 0s 68us/step - loss: 8.1279\n",
      "Epoch 11/50\n",
      "3356/3356 [==============================] - 0s 68us/step - loss: 7.9989\n",
      "Epoch 12/50\n",
      "3356/3356 [==============================] - 0s 60us/step - loss: 7.9408\n",
      "Epoch 13/50\n",
      "3356/3356 [==============================] - 0s 62us/step - loss: 7.8807\n",
      "Epoch 14/50\n",
      "3356/3356 [==============================] - 0s 65us/step - loss: 7.8440\n",
      "Epoch 15/50\n",
      "3356/3356 [==============================] - 0s 62us/step - loss: 7.7770\n",
      "Epoch 16/50\n",
      "3356/3356 [==============================] - 0s 61us/step - loss: 7.7427\n",
      "Epoch 17/50\n",
      "3356/3356 [==============================] - 0s 75us/step - loss: 7.7413\n",
      "Epoch 18/50\n",
      "3356/3356 [==============================] - 0s 62us/step - loss: 7.6945\n",
      "Epoch 19/50\n",
      "3356/3356 [==============================] - 0s 62us/step - loss: 7.6811\n",
      "Epoch 20/50\n",
      "3356/3356 [==============================] - 0s 69us/step - loss: 7.6565\n",
      "Epoch 21/50\n",
      "3356/3356 [==============================] - 0s 69us/step - loss: 7.6616\n",
      "Epoch 22/50\n",
      "3356/3356 [==============================] - 0s 63us/step - loss: 7.6268\n",
      "Epoch 23/50\n",
      "3356/3356 [==============================] - 0s 68us/step - loss: 7.6787\n",
      "Epoch 24/50\n",
      "3356/3356 [==============================] - 0s 80us/step - loss: 7.6975\n",
      "Epoch 25/50\n",
      "3356/3356 [==============================] - 0s 79us/step - loss: 7.6031\n",
      "Epoch 26/50\n",
      "3356/3356 [==============================] - 0s 77us/step - loss: 7.5416\n",
      "Epoch 27/50\n",
      "3356/3356 [==============================] - 0s 87us/step - loss: 7.5389\n",
      "Epoch 28/50\n",
      "3356/3356 [==============================] - 0s 70us/step - loss: 7.5394\n",
      "Epoch 29/50\n",
      "3356/3356 [==============================] - 0s 66us/step - loss: 7.5069\n",
      "Epoch 30/50\n",
      "3356/3356 [==============================] - 0s 61us/step - loss: 7.5420\n",
      "Epoch 31/50\n",
      "3356/3356 [==============================] - 0s 67us/step - loss: 7.5310\n",
      "Epoch 32/50\n",
      "3356/3356 [==============================] - 0s 65us/step - loss: 7.5601\n",
      "Epoch 33/50\n",
      "3356/3356 [==============================] - 0s 62us/step - loss: 7.4799\n",
      "Epoch 34/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 7.4520\n",
      "Epoch 35/50\n",
      "3356/3356 [==============================] - 0s 65us/step - loss: 7.4842\n",
      "Epoch 36/50\n",
      "3356/3356 [==============================] - 0s 65us/step - loss: 7.4810\n",
      "Epoch 37/50\n",
      "3356/3356 [==============================] - 0s 63us/step - loss: 7.4203\n",
      "Epoch 38/50\n",
      "3356/3356 [==============================] - 0s 63us/step - loss: 7.4163\n",
      "Epoch 39/50\n",
      "3356/3356 [==============================] - 0s 69us/step - loss: 7.4225\n",
      "Epoch 40/50\n",
      "3356/3356 [==============================] - 0s 78us/step - loss: 7.4012\n",
      "Epoch 41/50\n",
      "3356/3356 [==============================] - 0s 76us/step - loss: 7.3834\n",
      "Epoch 42/50\n",
      "3356/3356 [==============================] - 0s 74us/step - loss: 7.3624\n",
      "Epoch 43/50\n",
      "3356/3356 [==============================] - 0s 82us/step - loss: 7.4971\n",
      "Epoch 44/50\n",
      "3356/3356 [==============================] - 0s 72us/step - loss: 7.5531\n",
      "Epoch 45/50\n",
      "3356/3356 [==============================] - 0s 71us/step - loss: 7.4333\n",
      "Epoch 46/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 7.5000\n",
      "Epoch 47/50\n",
      "3356/3356 [==============================] - 0s 71us/step - loss: 7.4745\n",
      "Epoch 48/50\n",
      "3356/3356 [==============================] - 0s 66us/step - loss: 7.3606\n",
      "Epoch 49/50\n",
      "3356/3356 [==============================] - 0s 66us/step - loss: 7.3372\n",
      "Epoch 50/50\n",
      "3356/3356 [==============================] - 0s 71us/step - loss: 7.3393\n",
      "Best: -7.653400 using {'optimizer': 'Adam'}\n",
      "-8.310956 (0.864512) with: {'optimizer': 'SGD'}\n",
      "-7.798671 (0.266606) with: {'optimizer': 'RMSprop'}\n",
      "-7.880936 (0.373013) with: {'optimizer': 'Adagrad'}\n",
      "-7.774440 (0.364244) with: {'optimizer': 'Adadelta'}\n",
      "-7.653400 (0.376651) with: {'optimizer': 'Adam'}\n",
      "-7.807634 (0.352655) with: {'optimizer': 'Adamax'}\n",
      "-7.818225 (0.194464) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, verbose=1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate and Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "def create_model(lr=0.01, momentum=0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,\n",
    "                    input_dim=X_train.shape[1],\n",
    "                    #kernel_initializer='normal',\n",
    "                    activation='relu'                   \n",
    "                   ))\n",
    "    model.add(Dense(1,\n",
    "                   #kernel_initializer='normal',\n",
    "                   activation='linear'\n",
    "                   ))\n",
    "    model.compile(loss='mse', optimizer=SGD(lr=lr, momentum=momentum))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huypham/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "/home/huypham/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3356/3356 [==============================] - 1s 256us/step - loss: 15.9370\n",
      "Epoch 2/50\n",
      "3356/3356 [==============================] - 0s 57us/step - loss: 9.1777\n",
      "Epoch 3/50\n",
      "3356/3356 [==============================] - 0s 57us/step - loss: 8.3251\n",
      "Epoch 4/50\n",
      "3356/3356 [==============================] - 0s 60us/step - loss: 8.5354\n",
      "Epoch 5/50\n",
      "3356/3356 [==============================] - 0s 54us/step - loss: 8.0242\n",
      "Epoch 6/50\n",
      "3356/3356 [==============================] - 0s 54us/step - loss: 8.3384\n",
      "Epoch 7/50\n",
      "3356/3356 [==============================] - 0s 58us/step - loss: 8.3934\n",
      "Epoch 8/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 8.2491\n",
      "Epoch 9/50\n",
      "3356/3356 [==============================] - 0s 52us/step - loss: 8.4118\n",
      "Epoch 10/50\n",
      "3356/3356 [==============================] - 0s 48us/step - loss: 8.0667\n",
      "Epoch 11/50\n",
      "3356/3356 [==============================] - 0s 57us/step - loss: 8.0135\n",
      "Epoch 12/50\n",
      "3356/3356 [==============================] - 0s 53us/step - loss: 8.2585\n",
      "Epoch 13/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 7.8585\n",
      "Epoch 14/50\n",
      "3356/3356 [==============================] - 0s 54us/step - loss: 7.9210\n",
      "Epoch 15/50\n",
      "3356/3356 [==============================] - 0s 74us/step - loss: 7.7153\n",
      "Epoch 16/50\n",
      "3356/3356 [==============================] - 0s 74us/step - loss: 7.9430\n",
      "Epoch 17/50\n",
      "3356/3356 [==============================] - 0s 71us/step - loss: 7.8801\n",
      "Epoch 18/50\n",
      "3356/3356 [==============================] - 0s 88us/step - loss: 7.8181\n",
      "Epoch 19/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 7.8345\n",
      "Epoch 20/50\n",
      "3356/3356 [==============================] - 0s 74us/step - loss: 7.6526\n",
      "Epoch 21/50\n",
      "3356/3356 [==============================] - 0s 89us/step - loss: 7.7262\n",
      "Epoch 22/50\n",
      "3356/3356 [==============================] - 0s 71us/step - loss: 7.7690\n",
      "Epoch 23/50\n",
      "3356/3356 [==============================] - 0s 55us/step - loss: 7.8278\n",
      "Epoch 24/50\n",
      "3356/3356 [==============================] - 0s 61us/step - loss: 7.7825\n",
      "Epoch 25/50\n",
      "3356/3356 [==============================] - 0s 58us/step - loss: 7.5969\n",
      "Epoch 26/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 7.7575\n",
      "Epoch 27/50\n",
      "3356/3356 [==============================] - 0s 59us/step - loss: 7.7098\n",
      "Epoch 28/50\n",
      "3356/3356 [==============================] - 0s 58us/step - loss: 7.6406\n",
      "Epoch 29/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 7.8069\n",
      "Epoch 30/50\n",
      "3356/3356 [==============================] - 0s 53us/step - loss: 7.7692\n",
      "Epoch 31/50\n",
      "3356/3356 [==============================] - 0s 54us/step - loss: 7.7870\n",
      "Epoch 32/50\n",
      "3356/3356 [==============================] - 0s 55us/step - loss: 7.8199\n",
      "Epoch 33/50\n",
      "3356/3356 [==============================] - 0s 54us/step - loss: 7.4983\n",
      "Epoch 34/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 7.9368\n",
      "Epoch 35/50\n",
      "3356/3356 [==============================] - 0s 60us/step - loss: 7.5601\n",
      "Epoch 36/50\n",
      "3356/3356 [==============================] - 0s 64us/step - loss: 7.9174\n",
      "Epoch 37/50\n",
      "3356/3356 [==============================] - 0s 46us/step - loss: 7.8953\n",
      "Epoch 38/50\n",
      "3356/3356 [==============================] - 0s 57us/step - loss: 7.7162\n",
      "Epoch 39/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 7.5187\n",
      "Epoch 40/50\n",
      "3356/3356 [==============================] - 0s 55us/step - loss: 7.9067\n",
      "Epoch 41/50\n",
      "3356/3356 [==============================] - 0s 52us/step - loss: 7.9371\n",
      "Epoch 42/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 7.6092\n",
      "Epoch 43/50\n",
      "3356/3356 [==============================] - 0s 49us/step - loss: 7.8842\n",
      "Epoch 44/50\n",
      "3356/3356 [==============================] - 0s 59us/step - loss: 7.6041\n",
      "Epoch 45/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 7.6897\n",
      "Epoch 46/50\n",
      "3356/3356 [==============================] - 0s 60us/step - loss: 7.4799\n",
      "Epoch 47/50\n",
      "3356/3356 [==============================] - 0s 60us/step - loss: 7.6177\n",
      "Epoch 48/50\n",
      "3356/3356 [==============================] - 0s 54us/step - loss: 7.4381\n",
      "Epoch 49/50\n",
      "3356/3356 [==============================] - 0s 61us/step - loss: 7.9306\n",
      "Epoch 50/50\n",
      "3356/3356 [==============================] - 0s 55us/step - loss: 7.4523\n",
      "Best: -7.628198 using {'lr': 0.01, 'momentum': 0.8}\n",
      "-8.138315 (0.321730) with: {'lr': 0.001, 'momentum': 0.0}\n",
      "-7.996446 (0.387432) with: {'lr': 0.001, 'momentum': 0.2}\n",
      "-8.113032 (0.653978) with: {'lr': 0.001, 'momentum': 0.4}\n",
      "-7.920078 (0.288973) with: {'lr': 0.001, 'momentum': 0.6}\n",
      "-7.685408 (0.389325) with: {'lr': 0.001, 'momentum': 0.8}\n",
      "-8.056500 (0.566636) with: {'lr': 0.001, 'momentum': 0.9}\n",
      "-7.644691 (0.378297) with: {'lr': 0.01, 'momentum': 0.0}\n",
      "-7.922071 (0.495583) with: {'lr': 0.01, 'momentum': 0.2}\n",
      "-7.712552 (0.358810) with: {'lr': 0.01, 'momentum': 0.4}\n",
      "-8.984759 (1.485511) with: {'lr': 0.01, 'momentum': 0.6}\n",
      "-7.628198 (0.361565) with: {'lr': 0.01, 'momentum': 0.8}\n",
      "-8.183841 (0.608962) with: {'lr': 0.01, 'momentum': 0.9}\n",
      "-13.571375 (0.447239) with: {'lr': 0.1, 'momentum': 0.0}\n",
      "-13.531635 (0.444632) with: {'lr': 0.1, 'momentum': 0.2}\n",
      "-13.552640 (0.495691) with: {'lr': 0.1, 'momentum': 0.4}\n",
      "-13.554767 (0.429288) with: {'lr': 0.1, 'momentum': 0.6}\n",
      "-13.547782 (0.500943) with: {'lr': 0.1, 'momentum': 0.8}\n",
      "-13.606802 (0.379897) with: {'lr': 0.1, 'momentum': 0.9}\n",
      "-13.657360 (0.654043) with: {'lr': 0.2, 'momentum': 0.0}\n",
      "-13.628085 (0.386648) with: {'lr': 0.2, 'momentum': 0.2}\n",
      "nan (nan) with: {'lr': 0.2, 'momentum': 0.4}\n",
      "nan (nan) with: {'lr': 0.2, 'momentum': 0.6}\n",
      "-14.349021 (0.552368) with: {'lr': 0.2, 'momentum': 0.8}\n",
      "nan (nan) with: {'lr': 0.2, 'momentum': 0.9}\n",
      "nan (nan) with: {'lr': 0.3, 'momentum': 0.0}\n",
      "nan (nan) with: {'lr': 0.3, 'momentum': 0.2}\n",
      "nan (nan) with: {'lr': 0.3, 'momentum': 0.4}\n",
      "nan (nan) with: {'lr': 0.3, 'momentum': 0.6}\n",
      "nan (nan) with: {'lr': 0.3, 'momentum': 0.8}\n",
      "nan (nan) with: {'lr': 0.3, 'momentum': 0.9}\n"
     ]
    }
   ],
   "source": [
    "lr = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "param_grid = dict(lr=lr, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, verbose=1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "def create_model(activation='relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,\n",
    "                    input_dim=X_train.shape[1],\n",
    "                    #kernel_initializer='normal',\n",
    "                    activation=activation                   \n",
    "                   ))\n",
    "    model.add(Dense(1,\n",
    "                   #kernel_initializer='normal',\n",
    "                   activation='linear'\n",
    "                   ))\n",
    "    model.compile(loss='mse', optimizer='Nadam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=64, shuffle=True ,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3356/3356 [==============================] - 1s 384us/step - loss: 14.7218\n",
      "Epoch 2/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 9.8252\n",
      "Epoch 3/50\n",
      "3356/3356 [==============================] - 0s 71us/step - loss: 8.8356\n",
      "Epoch 4/50\n",
      "3356/3356 [==============================] - 0s 63us/step - loss: 8.5408\n",
      "Epoch 5/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 8.3756\n",
      "Epoch 6/50\n",
      "3356/3356 [==============================] - 0s 62us/step - loss: 8.2067\n",
      "Epoch 7/50\n",
      "3356/3356 [==============================] - 0s 78us/step - loss: 8.1634\n",
      "Epoch 8/50\n",
      "3356/3356 [==============================] - 0s 61us/step - loss: 7.9835\n",
      "Epoch 9/50\n",
      "3356/3356 [==============================] - 0s 66us/step - loss: 7.9668\n",
      "Epoch 10/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 7.8988\n",
      "Epoch 11/50\n",
      "3356/3356 [==============================] - 0s 88us/step - loss: 7.8601\n",
      "Epoch 12/50\n",
      "3356/3356 [==============================] - 0s 69us/step - loss: 7.8593\n",
      "Epoch 13/50\n",
      "3356/3356 [==============================] - 0s 70us/step - loss: 7.7998\n",
      "Epoch 14/50\n",
      "3356/3356 [==============================] - 0s 59us/step - loss: 7.8417\n",
      "Epoch 15/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 7.7344\n",
      "Epoch 16/50\n",
      "3356/3356 [==============================] - 0s 66us/step - loss: 7.7470\n",
      "Epoch 17/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 7.7826\n",
      "Epoch 18/50\n",
      "3356/3356 [==============================] - 0s 81us/step - loss: 7.7438\n",
      "Epoch 19/50\n",
      "3356/3356 [==============================] - 0s 72us/step - loss: 7.7001\n",
      "Epoch 20/50\n",
      "3356/3356 [==============================] - 0s 63us/step - loss: 7.6074\n",
      "Epoch 21/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 7.6039\n",
      "Epoch 22/50\n",
      "3356/3356 [==============================] - 0s 67us/step - loss: 7.5960\n",
      "Epoch 23/50\n",
      "3356/3356 [==============================] - 0s 53us/step - loss: 7.6451\n",
      "Epoch 24/50\n",
      "3356/3356 [==============================] - 0s 61us/step - loss: 7.5635\n",
      "Epoch 25/50\n",
      "3356/3356 [==============================] - 0s 72us/step - loss: 7.5700\n",
      "Epoch 26/50\n",
      "3356/3356 [==============================] - 0s 62us/step - loss: 7.6811\n",
      "Epoch 27/50\n",
      "3356/3356 [==============================] - 0s 72us/step - loss: 7.5461\n",
      "Epoch 28/50\n",
      "3356/3356 [==============================] - 0s 83us/step - loss: 7.5929\n",
      "Epoch 29/50\n",
      "3356/3356 [==============================] - 0s 81us/step - loss: 7.5165\n",
      "Epoch 30/50\n",
      "3356/3356 [==============================] - 0s 82us/step - loss: 7.5574\n",
      "Epoch 31/50\n",
      "3356/3356 [==============================] - 0s 67us/step - loss: 7.5530\n",
      "Epoch 32/50\n",
      "3356/3356 [==============================] - 0s 67us/step - loss: 7.5475\n",
      "Epoch 33/50\n",
      "3356/3356 [==============================] - 0s 69us/step - loss: 7.4354\n",
      "Epoch 34/50\n",
      "3356/3356 [==============================] - 0s 69us/step - loss: 7.3751\n",
      "Epoch 35/50\n",
      "3356/3356 [==============================] - 0s 63us/step - loss: 7.4308\n",
      "Epoch 36/50\n",
      "3356/3356 [==============================] - 0s 58us/step - loss: 7.4403\n",
      "Epoch 37/50\n",
      "3356/3356 [==============================] - 0s 78us/step - loss: 7.4256\n",
      "Epoch 38/50\n",
      "3356/3356 [==============================] - 0s 69us/step - loss: 7.4663\n",
      "Epoch 39/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 7.4199\n",
      "Epoch 40/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 7.3883\n",
      "Epoch 41/50\n",
      "3356/3356 [==============================] - 0s 71us/step - loss: 7.4246\n",
      "Epoch 42/50\n",
      "3356/3356 [==============================] - 0s 77us/step - loss: 7.4361\n",
      "Epoch 43/50\n",
      "3356/3356 [==============================] - 0s 71us/step - loss: 7.4202\n",
      "Epoch 44/50\n",
      "3356/3356 [==============================] - 0s 75us/step - loss: 7.4021\n",
      "Epoch 45/50\n",
      "3356/3356 [==============================] - 0s 78us/step - loss: 7.3744\n",
      "Epoch 46/50\n",
      "3356/3356 [==============================] - 0s 75us/step - loss: 7.3278\n",
      "Epoch 47/50\n",
      "3356/3356 [==============================] - 0s 72us/step - loss: 7.3607\n",
      "Epoch 48/50\n",
      "3356/3356 [==============================] - 0s 68us/step - loss: 7.3149\n",
      "Epoch 49/50\n",
      "3356/3356 [==============================] - 0s 78us/step - loss: 7.4400\n",
      "Epoch 50/50\n",
      "3356/3356 [==============================] - 0s 92us/step - loss: 7.3606\n",
      "Best: -7.580658 using {'activation': 'relu'}\n",
      "-13.949621 (0.593437) with: {'activation': 'softmax'}\n",
      "-7.772418 (0.409555) with: {'activation': 'softplus'}\n",
      "-7.648948 (0.487423) with: {'activation': 'softsign'}\n",
      "-7.580658 (0.364221) with: {'activation': 'relu'}\n",
      "-7.638037 (0.360424) with: {'activation': 'tanh'}\n",
      "-7.924758 (0.746699) with: {'activation': 'sigmoid'}\n",
      "-7.696667 (0.336030) with: {'activation': 'hard_sigmoid'}\n",
      "-7.968354 (0.553951) with: {'activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "activation = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init_mode='uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64,\n",
    "                    input_dim=X_train.shape[1],\n",
    "                    #kernel_initializer='normal',\n",
    "                    activation='tanh',\n",
    "                    kernel_initializer=init_mode\n",
    "                   ))\n",
    "    model.add(Dense(1,\n",
    "                   #kernel_initializer='normal',\n",
    "                   activation='linear'\n",
    "                   ))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3356/3356 [==============================] - 1s 340us/step - loss: 15.9557\n",
      "Epoch 2/100\n",
      "3356/3356 [==============================] - 0s 53us/step - loss: 12.2777\n",
      "Epoch 3/100\n",
      "3356/3356 [==============================] - 0s 40us/step - loss: 10.5823\n",
      "Epoch 4/100\n",
      "3356/3356 [==============================] - 0s 42us/step - loss: 9.3398\n",
      "Epoch 5/100\n",
      "3356/3356 [==============================] - 0s 41us/step - loss: 8.7040\n",
      "Epoch 6/100\n",
      "3356/3356 [==============================] - 0s 55us/step - loss: 8.4263\n",
      "Epoch 7/100\n",
      "3356/3356 [==============================] - 0s 40us/step - loss: 8.3415\n",
      "Epoch 8/100\n",
      "3356/3356 [==============================] - 0s 38us/step - loss: 8.1226\n",
      "Epoch 9/100\n",
      "3356/3356 [==============================] - 0s 38us/step - loss: 8.0454\n",
      "Epoch 10/100\n",
      "3356/3356 [==============================] - 0s 42us/step - loss: 7.9791\n",
      "Epoch 11/100\n",
      "3356/3356 [==============================] - 0s 37us/step - loss: 7.9114\n",
      "Epoch 12/100\n",
      "3356/3356 [==============================] - 0s 36us/step - loss: 7.9067\n",
      "Epoch 13/100\n",
      "3356/3356 [==============================] - 0s 41us/step - loss: 7.9294\n",
      "Epoch 14/100\n",
      "3356/3356 [==============================] - 0s 38us/step - loss: 7.9077\n",
      "Epoch 15/100\n",
      "3356/3356 [==============================] - 0s 39us/step - loss: 7.9743\n",
      "Epoch 16/100\n",
      "3356/3356 [==============================] - 0s 42us/step - loss: 7.7833\n",
      "Epoch 17/100\n",
      "3356/3356 [==============================] - 0s 36us/step - loss: 7.7239\n",
      "Epoch 18/100\n",
      "3356/3356 [==============================] - 0s 43us/step - loss: 7.7459\n",
      "Epoch 19/100\n",
      "3356/3356 [==============================] - 0s 34us/step - loss: 7.7099\n",
      "Epoch 20/100\n",
      "3356/3356 [==============================] - 0s 42us/step - loss: 7.7246\n",
      "Epoch 21/100\n",
      "3356/3356 [==============================] - 0s 39us/step - loss: 7.6213\n",
      "Epoch 22/100\n",
      "3356/3356 [==============================] - 0s 42us/step - loss: 7.6272\n",
      "Epoch 23/100\n",
      "3356/3356 [==============================] - 0s 31us/step - loss: 7.6737\n",
      "Epoch 24/100\n",
      "3356/3356 [==============================] - 0s 34us/step - loss: 7.6104\n",
      "Epoch 25/100\n",
      "3356/3356 [==============================] - 0s 40us/step - loss: 7.6056\n",
      "Epoch 26/100\n",
      "3356/3356 [==============================] - 0s 50us/step - loss: 7.6206\n",
      "Epoch 27/100\n",
      "3356/3356 [==============================] - 0s 46us/step - loss: 7.5629\n",
      "Epoch 28/100\n",
      "3356/3356 [==============================] - 0s 41us/step - loss: 7.5199\n",
      "Epoch 29/100\n",
      "3356/3356 [==============================] - 0s 39us/step - loss: 7.5485\n",
      "Epoch 30/100\n",
      "3356/3356 [==============================] - 0s 34us/step - loss: 7.5620\n",
      "Epoch 31/100\n",
      "3356/3356 [==============================] - 0s 40us/step - loss: 7.5377\n",
      "Epoch 32/100\n",
      "3356/3356 [==============================] - 0s 33us/step - loss: 7.5302\n",
      "Epoch 33/100\n",
      "3356/3356 [==============================] - 0s 37us/step - loss: 7.4927\n",
      "Epoch 34/100\n",
      "3356/3356 [==============================] - 0s 38us/step - loss: 7.4658\n",
      "Epoch 35/100\n",
      "3356/3356 [==============================] - 0s 48us/step - loss: 7.4924\n",
      "Epoch 36/100\n",
      "3356/3356 [==============================] - 0s 46us/step - loss: 7.4720\n",
      "Epoch 37/100\n",
      "3356/3356 [==============================] - 0s 43us/step - loss: 7.4682\n",
      "Epoch 38/100\n",
      "3356/3356 [==============================] - 0s 35us/step - loss: 7.4113\n",
      "Epoch 39/100\n",
      "3356/3356 [==============================] - 0s 33us/step - loss: 7.3975\n",
      "Epoch 40/100\n",
      "3356/3356 [==============================] - 0s 36us/step - loss: 7.4326\n",
      "Epoch 41/100\n",
      "3356/3356 [==============================] - 0s 40us/step - loss: 7.4979\n",
      "Epoch 42/100\n",
      "3356/3356 [==============================] - 0s 43us/step - loss: 7.4158\n",
      "Epoch 43/100\n",
      "3356/3356 [==============================] - 0s 38us/step - loss: 7.5237\n",
      "Epoch 44/100\n",
      "3356/3356 [==============================] - 0s 40us/step - loss: 7.3469\n",
      "Epoch 45/100\n",
      "3356/3356 [==============================] - 0s 34us/step - loss: 7.4252\n",
      "Epoch 46/100\n",
      "3356/3356 [==============================] - 0s 38us/step - loss: 7.3860\n",
      "Epoch 47/100\n",
      "3356/3356 [==============================] - 0s 38us/step - loss: 7.5265\n",
      "Epoch 48/100\n",
      "3356/3356 [==============================] - 0s 37us/step - loss: 7.3627\n",
      "Epoch 49/100\n",
      "3356/3356 [==============================] - 0s 37us/step - loss: 7.3902\n",
      "Epoch 50/100\n",
      "3356/3356 [==============================] - 0s 38us/step - loss: 7.3600\n",
      "Epoch 51/100\n",
      "3356/3356 [==============================] - 0s 33us/step - loss: 7.3600\n",
      "Epoch 52/100\n",
      "3356/3356 [==============================] - 0s 34us/step - loss: 7.3187\n",
      "Epoch 53/100\n",
      "3356/3356 [==============================] - 0s 39us/step - loss: 7.3740\n",
      "Epoch 54/100\n",
      "3356/3356 [==============================] - 0s 41us/step - loss: 7.3771\n",
      "Epoch 55/100\n",
      "3356/3356 [==============================] - 0s 40us/step - loss: 7.3745\n",
      "Epoch 56/100\n",
      "3356/3356 [==============================] - 0s 39us/step - loss: 7.3281\n",
      "Epoch 57/100\n",
      "3356/3356 [==============================] - 0s 42us/step - loss: 7.3588\n",
      "Epoch 58/100\n",
      "3356/3356 [==============================] - 0s 38us/step - loss: 7.3098\n",
      "Epoch 59/100\n",
      "3356/3356 [==============================] - 0s 41us/step - loss: 7.3535\n",
      "Epoch 60/100\n",
      "3356/3356 [==============================] - 0s 44us/step - loss: 7.4384\n",
      "Epoch 61/100\n",
      "3356/3356 [==============================] - 0s 41us/step - loss: 7.3527\n",
      "Epoch 62/100\n",
      "3356/3356 [==============================] - 0s 51us/step - loss: 7.2683\n",
      "Epoch 63/100\n",
      "3356/3356 [==============================] - 0s 40us/step - loss: 7.4980\n",
      "Epoch 64/100\n",
      "3356/3356 [==============================] - 0s 40us/step - loss: 7.2858\n",
      "Epoch 65/100\n",
      "3356/3356 [==============================] - 0s 32us/step - loss: 7.3671\n",
      "Epoch 66/100\n",
      "3356/3356 [==============================] - 0s 34us/step - loss: 7.2613\n",
      "Epoch 67/100\n",
      "3356/3356 [==============================] - 0s 39us/step - loss: 7.2829\n",
      "Epoch 68/100\n",
      "3356/3356 [==============================] - 0s 36us/step - loss: 7.2684\n",
      "Epoch 69/100\n",
      "3356/3356 [==============================] - 0s 37us/step - loss: 7.2612\n",
      "Epoch 70/100\n",
      "3356/3356 [==============================] - 0s 36us/step - loss: 7.3565\n",
      "Epoch 71/100\n",
      "3356/3356 [==============================] - 0s 36us/step - loss: 7.4667\n",
      "Epoch 72/100\n",
      "3356/3356 [==============================] - 0s 41us/step - loss: 7.2510\n",
      "Epoch 73/100\n",
      "3356/3356 [==============================] - 0s 31us/step - loss: 7.2656\n",
      "Epoch 74/100\n",
      "3356/3356 [==============================] - 0s 41us/step - loss: 7.2575\n",
      "Epoch 75/100\n",
      "3356/3356 [==============================] - 0s 40us/step - loss: 7.2053\n",
      "Epoch 76/100\n",
      "3356/3356 [==============================] - 0s 41us/step - loss: 7.3086\n",
      "Epoch 77/100\n",
      "3356/3356 [==============================] - 0s 45us/step - loss: 7.2153\n",
      "Epoch 78/100\n",
      "3356/3356 [==============================] - 0s 44us/step - loss: 7.2236\n",
      "Epoch 79/100\n",
      "3356/3356 [==============================] - 0s 47us/step - loss: 7.3797\n",
      "Epoch 80/100\n",
      "3356/3356 [==============================] - 0s 43us/step - loss: 7.2399\n",
      "Epoch 81/100\n",
      "3356/3356 [==============================] - 0s 53us/step - loss: 7.2106\n",
      "Epoch 82/100\n",
      "3356/3356 [==============================] - 0s 47us/step - loss: 7.2291\n",
      "Epoch 83/100\n",
      "3356/3356 [==============================] - 0s 47us/step - loss: 7.2261\n",
      "Epoch 84/100\n",
      "3356/3356 [==============================] - 0s 40us/step - loss: 7.3103\n",
      "Epoch 85/100\n",
      "3356/3356 [==============================] - 0s 39us/step - loss: 7.2822\n",
      "Epoch 86/100\n",
      "3356/3356 [==============================] - 0s 41us/step - loss: 7.2976\n",
      "Epoch 87/100\n",
      "3356/3356 [==============================] - 0s 44us/step - loss: 7.3163\n",
      "Epoch 88/100\n",
      "3356/3356 [==============================] - 0s 54us/step - loss: 7.2587\n",
      "Epoch 89/100\n",
      "3356/3356 [==============================] - 0s 57us/step - loss: 7.2736\n",
      "Epoch 90/100\n",
      "3356/3356 [==============================] - 0s 45us/step - loss: 7.2471\n",
      "Epoch 91/100\n",
      "3356/3356 [==============================] - 0s 44us/step - loss: 7.1843\n",
      "Epoch 92/100\n",
      "3356/3356 [==============================] - 0s 43us/step - loss: 7.1654\n",
      "Epoch 93/100\n",
      "3356/3356 [==============================] - 0s 42us/step - loss: 7.1718\n",
      "Epoch 94/100\n",
      "3356/3356 [==============================] - 0s 42us/step - loss: 7.2161\n",
      "Epoch 95/100\n",
      "3356/3356 [==============================] - 0s 36us/step - loss: 7.1896\n",
      "Epoch 96/100\n",
      "3356/3356 [==============================] - 0s 45us/step - loss: 7.1800\n",
      "Epoch 97/100\n",
      "3356/3356 [==============================] - 0s 42us/step - loss: 7.2170\n",
      "Epoch 98/100\n",
      "3356/3356 [==============================] - 0s 37us/step - loss: 7.1524\n",
      "Epoch 99/100\n",
      "3356/3356 [==============================] - 0s 40us/step - loss: 7.1196\n",
      "Epoch 100/100\n",
      "3356/3356 [==============================] - 0s 35us/step - loss: 7.1388\n",
      "Best: -7.476270 using {'init_mode': 'lecun_uniform'}\n",
      "-7.665706 (0.578881) with: {'init_mode': 'uniform'}\n",
      "-7.476270 (0.387881) with: {'init_mode': 'lecun_uniform'}\n",
      "-7.496248 (0.433780) with: {'init_mode': 'normal'}\n",
      "-7.497740 (0.368669) with: {'init_mode': 'zero'}\n",
      "-7.495214 (0.363143) with: {'init_mode': 'glorot_normal'}\n",
      "-7.480811 (0.390385) with: {'init_mode': 'glorot_uniform'}\n",
      "-7.489679 (0.411178) with: {'init_mode': 'he_normal'}\n",
      "-7.532432 (0.376852) with: {'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, verbose=1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def create_model(dropout_rate=0.0, weight_constraint=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], kernel_initializer='lecun_uniform', activation='softsign', kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer='lecun_uniform', activation='linear'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs=50, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3356/3356 [==============================] - 1s 411us/step - loss: 17.6253\n",
      "Epoch 2/50\n",
      "3356/3356 [==============================] - 0s 57us/step - loss: 13.7168\n",
      "Epoch 3/50\n",
      "3356/3356 [==============================] - 0s 57us/step - loss: 13.1289\n",
      "Epoch 4/50\n",
      "3356/3356 [==============================] - 0s 55us/step - loss: 12.1986\n",
      "Epoch 5/50\n",
      "3356/3356 [==============================] - 0s 59us/step - loss: 11.0131\n",
      "Epoch 6/50\n",
      "3356/3356 [==============================] - 0s 61us/step - loss: 9.9498\n",
      "Epoch 7/50\n",
      "3356/3356 [==============================] - 0s 59us/step - loss: 9.2321\n",
      "Epoch 8/50\n",
      "3356/3356 [==============================] - 0s 61us/step - loss: 8.8285\n",
      "Epoch 9/50\n",
      "3356/3356 [==============================] - 0s 59us/step - loss: 8.6449\n",
      "Epoch 10/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 8.5970\n",
      "Epoch 11/50\n",
      "3356/3356 [==============================] - 0s 55us/step - loss: 8.4063\n",
      "Epoch 12/50\n",
      "3356/3356 [==============================] - 0s 59us/step - loss: 8.2729\n",
      "Epoch 13/50\n",
      "3356/3356 [==============================] - 0s 73us/step - loss: 8.2490\n",
      "Epoch 14/50\n",
      "3356/3356 [==============================] - 0s 62us/step - loss: 8.0600\n",
      "Epoch 15/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 8.1719\n",
      "Epoch 16/50\n",
      "3356/3356 [==============================] - 0s 80us/step - loss: 8.0428\n",
      "Epoch 17/50\n",
      "3356/3356 [==============================] - 0s 57us/step - loss: 8.1499\n",
      "Epoch 18/50\n",
      "3356/3356 [==============================] - 0s 54us/step - loss: 8.0208\n",
      "Epoch 19/50\n",
      "3356/3356 [==============================] - 0s 53us/step - loss: 8.0510\n",
      "Epoch 20/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 7.9418\n",
      "Epoch 21/50\n",
      "3356/3356 [==============================] - 0s 57us/step - loss: 8.0226\n",
      "Epoch 22/50\n",
      "3356/3356 [==============================] - 0s 57us/step - loss: 8.0621\n",
      "Epoch 23/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 7.9640\n",
      "Epoch 24/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 7.9087\n",
      "Epoch 25/50\n",
      "3356/3356 [==============================] - 0s 60us/step - loss: 7.9991\n",
      "Epoch 26/50\n",
      "3356/3356 [==============================] - 0s 64us/step - loss: 7.8891\n",
      "Epoch 27/50\n",
      "3356/3356 [==============================] - 0s 60us/step - loss: 7.9193\n",
      "Epoch 28/50\n",
      "3356/3356 [==============================] - 0s 58us/step - loss: 7.8195\n",
      "Epoch 29/50\n",
      "3356/3356 [==============================] - 0s 57us/step - loss: 7.8709\n",
      "Epoch 30/50\n",
      "3356/3356 [==============================] - 0s 59us/step - loss: 7.8811\n",
      "Epoch 31/50\n",
      "3356/3356 [==============================] - 0s 61us/step - loss: 7.8621\n",
      "Epoch 32/50\n",
      "3356/3356 [==============================] - 0s 64us/step - loss: 7.7723\n",
      "Epoch 33/50\n",
      "3356/3356 [==============================] - 0s 55us/step - loss: 7.7562\n",
      "Epoch 34/50\n",
      "3356/3356 [==============================] - 0s 61us/step - loss: 7.8911\n",
      "Epoch 35/50\n",
      "3356/3356 [==============================] - 0s 75us/step - loss: 7.7166\n",
      "Epoch 36/50\n",
      "3356/3356 [==============================] - 0s 68us/step - loss: 7.8235\n",
      "Epoch 37/50\n",
      "3356/3356 [==============================] - 0s 63us/step - loss: 7.7376\n",
      "Epoch 38/50\n",
      "3356/3356 [==============================] - 0s 59us/step - loss: 7.8059\n",
      "Epoch 39/50\n",
      "3356/3356 [==============================] - 0s 59us/step - loss: 7.7659\n",
      "Epoch 40/50\n",
      "3356/3356 [==============================] - 0s 67us/step - loss: 7.7778\n",
      "Epoch 41/50\n",
      "3356/3356 [==============================] - 0s 61us/step - loss: 7.8819\n",
      "Epoch 42/50\n",
      "3356/3356 [==============================] - 0s 75us/step - loss: 7.7997\n",
      "Epoch 43/50\n",
      "3356/3356 [==============================] - 0s 66us/step - loss: 7.8275\n",
      "Epoch 44/50\n",
      "3356/3356 [==============================] - 0s 59us/step - loss: 7.7415\n",
      "Epoch 45/50\n",
      "3356/3356 [==============================] - 0s 60us/step - loss: 7.6997\n",
      "Epoch 46/50\n",
      "3356/3356 [==============================] - 0s 58us/step - loss: 7.6603\n",
      "Epoch 47/50\n",
      "3356/3356 [==============================] - 0s 56us/step - loss: 7.6787\n",
      "Epoch 48/50\n",
      "3356/3356 [==============================] - 0s 59us/step - loss: 7.6073\n",
      "Epoch 49/50\n",
      "3356/3356 [==============================] - 0s 68us/step - loss: 7.6926\n",
      "Epoch 50/50\n",
      "3356/3356 [==============================] - 0s 60us/step - loss: 7.5856\n",
      "Best: -7.667227 using {'dropout_rate': 0.2, 'weight_constraint': 5}\n",
      "-7.765184 (0.438064) with: {'dropout_rate': 0.0, 'weight_constraint': 1}\n",
      "-7.680581 (0.347787) with: {'dropout_rate': 0.0, 'weight_constraint': 3}\n",
      "-7.687535 (0.369863) with: {'dropout_rate': 0.0, 'weight_constraint': 5}\n",
      "-7.691773 (0.349052) with: {'dropout_rate': 0.2, 'weight_constraint': 1}\n",
      "-7.693025 (0.364618) with: {'dropout_rate': 0.2, 'weight_constraint': 3}\n",
      "-7.667227 (0.342051) with: {'dropout_rate': 0.2, 'weight_constraint': 5}\n",
      "-7.840004 (0.324054) with: {'dropout_rate': 0.4, 'weight_constraint': 1}\n",
      "-7.903156 (0.459118) with: {'dropout_rate': 0.4, 'weight_constraint': 3}\n",
      "-7.768475 (0.360080) with: {'dropout_rate': 0.4, 'weight_constraint': 5}\n",
      "-7.965698 (0.326251) with: {'dropout_rate': 0.6, 'weight_constraint': 1}\n",
      "-7.954020 (0.402318) with: {'dropout_rate': 0.6, 'weight_constraint': 3}\n",
      "-7.960029 (0.412755) with: {'dropout_rate': 0.6, 'weight_constraint': 5}\n",
      "-8.292903 (0.436858) with: {'dropout_rate': 0.8, 'weight_constraint': 1}\n",
      "-8.282564 (0.437542) with: {'dropout_rate': 0.8, 'weight_constraint': 3}\n",
      "-8.311785 (0.440664) with: {'dropout_rate': 0.8, 'weight_constraint': 5}\n",
      "-8.909653 (0.586476) with: {'dropout_rate': 0.9, 'weight_constraint': 1}\n",
      "-8.926709 (0.760882) with: {'dropout_rate': 0.9, 'weight_constraint': 3}\n",
      "-8.776543 (0.368353) with: {'dropout_rate': 0.9, 'weight_constraint': 5}\n"
     ]
    }
   ],
   "source": [
    "weight_constraint = [1, 3, 5]\n",
    "dropout_rate = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, verbose=1)\n",
    "grid_result = grid.fit(X_train_scaled, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def create_model(activation='relu', init_mode='lecun_uniform', dropout_rate=0.2, weight_constraint=5, optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, \n",
    "                    input_dim=X_train.shape[1], \n",
    "                    kernel_initializer=init_mode, \n",
    "                    activation=activation, \n",
    "                    kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='linear'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(build_fn=create_model, epochs=500, batch_size=64, verbose=0, shuffle=True)\n",
    "model_history=model.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.544357703112813"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test_scaled)\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "mse(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'loss'])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_test = pd.read_csv('ft_big_set_test.csv')\n",
    "ft_test = ft_test[df.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub = scaler.transform(ft_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.8859687, 5.9117546, 6.34465  , ..., 2.9169452, 2.8073382,\n",
       "       8.417611 ], dtype=float32)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_pred = model.predict(X_sub)\n",
    "sub_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub.time_to_failure = sub_pred\n",
    "sub.to_csv('NN_opt_big_ft_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
